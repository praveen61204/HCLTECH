{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4Dyc6hus9SePFSSkZy4MP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveen61204/HCLTECH/blob/master/project/quality%20inspection/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-k6fMedGloX",
        "outputId": "314387ab-3652-4f69-b38f-ff2bec06cfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==1.3.0\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.0) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.0) (6.0.3)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.0)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.0) (4.12.0.88)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.6.0)\n",
            "Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "Successfully installed albumentations-1.3.0 qudida-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==1.3.0 opencv-python torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "class DAGMClassificationDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_file, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        if not os.path.exists(label_file):\n",
        "            print(f\"Warning: Label file not found at {label_file}\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            with open(label_file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "            print(f\"DEBUG: Read {len(lines)} lines from {label_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label file {label_file}: {e}\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(img_dir):\n",
        "            print(f\"Warning: Image directory not found at {img_dir}\")\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 2:\n",
        "                img_name = parts[0]\n",
        "                label = int(parts[1])\n",
        "                # Try common image extensions\n",
        "                found_image_path = None\n",
        "                for ext in ['.PNG', '.jpg', '.jpeg']:\n",
        "                    img_path_with_ext = os.path.join(img_dir, img_name + ext)\n",
        "                    if os.path.exists(img_path_with_ext):\n",
        "                        found_image_path = img_path_with_ext\n",
        "                        break\n",
        "\n",
        "                if found_image_path:\n",
        "                    self.image_paths.append(found_image_path)\n",
        "                    self.labels.append(label)\n",
        "                else:\n",
        "                    print(f\"Warning: Image not found: {os.path.join(img_dir, img_name)} (tried .png, .jpg, .jpeg)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.image_paths[idx])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/HCL/DAGM/Class10/Train/images\"\n",
        "train_labels = \"/content/drive/MyDrive/HCL/DAGM/Class10/Train/Label/Labels.txt\"\n",
        "\n",
        "test_dir = \"/content/drive/MyDrive/HCL/DAGM/Class10/Test/images\"\n",
        "test_labels = \"/content/drive/MyDrive/HCL/DAGM/Class10/Test/Label/Labels.txt\"\n",
        "\n",
        "# --- Debugging additions ---\n",
        "print(f\"Checking existence of train_dir: {os.path.exists(train_dir)}\")\n",
        "print(f\"Checking existence of train_labels file: {os.path.exists(train_labels)}\")\n",
        "print(f\"Checking existence of test_dir: {os.path.exists(test_dir)}\")\n",
        "print(f\"Checking existence of test_labels file: {os.path.exists(test_labels)}\")\n",
        "\n",
        "train_dataset = DAGMClassificationDataset(train_dir, train_labels, transform=transform)\n",
        "test_dataset = DAGMClassificationDataset(test_dir, test_labels, transform=transform)\n",
        "\n",
        "print(f\"Number of samples in train_dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in test_dataset: {len(test_dataset)}\")\n",
        "\n",
        "if len(train_dataset) == 0:\n",
        "    raise ValueError(\"Train dataset is empty. Please check train_dir and train_labels paths and content.\")\n",
        "if len(test_dataset) == 0:\n",
        "    raise ValueError(\"Test dataset is empty. Please check test_dir and test_labels paths and content.\")\n",
        "# --- End Debugging additions ---\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: defect / non-defect\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"✅ Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "torch.save(model.state_dict(), \"dagm_resnet_classifier.pth\")\n",
        "print(\"Model saved successfully ✅\")"
      ],
      "metadata": {
        "id": "tOoOUs61IC5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a48b23a-ded5-49fc-f413-17e1066a2029"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking existence of train_dir: True\n",
            "Checking existence of train_labels file: True\n",
            "Checking existence of test_dir: True\n",
            "Checking existence of test_labels file: True\n",
            "DEBUG: Read 1151 lines from /content/drive/MyDrive/HCL/DAGM/Class10/Train/Label/Labels.txt\n",
            "DEBUG: Read 1151 lines from /content/drive/MyDrive/HCL/DAGM/Class10/Test/Label/Labels.txt\n",
            "Number of samples in train_dataset: 1150\n",
            "Number of samples in test_dataset: 1150\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3221\n",
            "Epoch [2/5], Loss: 0.0217\n",
            "Epoch [3/5], Loss: 0.0225\n",
            "Epoch [4/5], Loss: 0.0198\n",
            "Epoch [5/5], Loss: 0.0138\n",
            "✅ Test Accuracy: 99.91%\n",
            "Model saved successfully ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppXbEhsWITtS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}